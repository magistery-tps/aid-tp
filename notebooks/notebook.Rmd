---
title: |
    | Maestría en Explotación de datos y Descubrimiento de conocimiento
    |
    | Materia: Análisis inteligente de datos
    |
    | Trabajo práctico: Asteroides Peligrosos
author: "Adrian Norberto Marino"
date: "2021/08/01"
output:
  html_document:
    highlight: tango
    theme: sandstone
    df_print: paged
    includes:
      after_body: ./footer.html
---

<style>
h1, .h1, h2, .h2, h3, .h3 {
  margin-top: 64px;
}
.observations { 
  background-color:#e6f0ff; 
  border-color: #33ccff;
  border-style: solid;
  border-width: 1px;
  border-radius: 5px; 
  padding: 15px;
}
</style>

<a href="https://github.com/magistery-tps/aid-tp" class="github-corner" aria-label="View source on GitHub" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>


```{r, echo=TRUE, include=TRUE}
options(warn=-2)
library(pacman)
p_load(dplyr)
source('../lib/import.R')
#
# Es una librería de funciones comunes desarrolladas a partir de este TP.
import('../lib/common-lib.R')
#
# Funciones especificas para este TP.
import('../scripts/helper_functions.R')
```

```{r, echo=TRUE}
set.seed(1)
```

## 1. Cargamos el dataset


### 1.1. Cargamos el dataset [nasa-asteroids](https://www.kaggle.com/shrutimehta/nasa-asteroids-classification) y excluirnos observaciones con valores faltaste.

```{r}
dataset <- loadcsv('../datasets/nasa.csv')
str(dataset)
```

### 1.2. Las siguientes columnas las excluimos ya sea por que son no numerica, o colineales con las columna que si son parte de nuestro analisis.

```{r, echo=TRUE}
excluded_columns <- c(
  'Neo.Reference.ID',
  'Name',
  'Close.Approach.Date',
  'Epoch.Date.Close.Approach',
  'Orbit.ID',
  'Orbit.Determination.Date',
  'Orbiting.Body',
  'Est.Dia.in.Feet.min.',
  'Est.Dia.in.Feet.max.',
  'Est.Dia.in.M.min.',
  'Est.Dia.in.M.max.',
  'Est.Dia.in.KM.min.',
  'Est.Dia.in.KM.max.',
  'Equinox',
  'Orbit.Uncertainity'
)

ds_step_1 <- dataset %>% dplyr::select(-excluded_columns) %>% na.omit
rm(dataset)

str(ds_step_1)
```


### 1.3. Tomamo una muestra del 80% del dataset.

La idea de este paso es evitar tener los mismos resultado que otros análisis 
pre-existentes en kaggle. Para esto ordenamos aleatoria-mente las observaciones 
con el parámetro shuffle y luego tomamos una muestra del 80% de las observaciones.


```{r}
c(ds_step_2, any) %<-% train_test_split(
  ds_step_1, 
  train_size = .8, 
  shuffle    = TRUE
)
rm(any)
rm(ds_step_1)
```


## 2. Eliminamos las columnas que están altamente co-relacionadas

Excluimos las columnas que tienen un correlación mayor al 80%. 
Del grupo altamenten correlacionesdos nos quedamos con una sola variable ya 
que todas con muy simialres.

```{r}
high_correlated_columns <- find_high_correlated_columns(
  feat(ds_step_2), 
  cutoff=.9
)

ds_step_3 <- ds_step_2 %>% dplyr::select(-high_correlated_columns[-1])

rm(ds_step_2)
str(ds_step_3)
```

## 3. Tomamos las columnas que mejor separan las clases.

Para realizar este paso vamos a utilizar la función `feature_importance` 
del algoritmo Random Forest. Esta función nos permite comparar las variables 
descuerdo a cuan buenas son para separa las clases. Luego tomaremos las 5
variables que mejor separa las clases.

```{r, echo=TRUE, fig.align='center'}
result <- features_importance(ds_step_3, target = 'Hazardous')
result

plot_features_importance(result)

n_best_features = 5
# n_best_features = 15

best_features <- top_acc_features(result, top=n_best_features)
best_features
length(best_features)

ds_step_4 <- ds_step_3 %>% dplyr::select(c(best_features, c(Hazardous)))

rm(ds_step_3)
```

```{r}
str(ds_step_4)
```

## 4. Filtramos outliers

```{r}
ds_step_5 <- filter_outliers_m1(ds_step_4, max_score = 0.51)
# ds_step_5 <- filter_outliers_m2(ds_step_4)

rm(ds_step_4)
```


## 5. Transformamos la varaible a predecir a tipo numericas

```{r}
ds_step_6 <- ds_step_5 %>% 
  mutate(Hazardous = case_when(Hazardous %in% c('True') ~ 1, TRUE ~ 0))

rm(ds_step_5)
str(ds_step_6)
```


## 6. Análisis Exploratorio

### 6.1. Boxplot comparativos
```{r, fig.align='center'}
coparative_boxplot(feat(ds_step_6), to_col=n_best_features)
```


### 6.2. Histogramas y densidad

```{r, fig.align='center'}
comparative_histplot(feat(ds_step_6), to_col=n_best_features)
```

### 6.3. Analizamos gráfico de normalidad univariado

```{r, echo=FALSE, fig.align='center'}
comparative_qqplot(feat(ds_step_6), to_col=n_best_features)
```
**Observaciones**: Al parecer  solo Perihelion.Distance parece ser normal 
o por lo enos la mas nromal de todas.


### 6.3. Test de normalidad uni-variado

```{r}
uni_shapiro_test(feat(ds_step_6))
```

**Observaciones**: En todos los casos el p-valor < 0.05 y se rechaza 
normalidad en todas las variables. Esto coincido con los qqplot donde en 
todos los casos no son normales salvo Perihelion.Distance que parece 
tender anormalidad.

### 6.4. Test de normalidad muti-variado

```{r}
mult_shapiro_test(feat(ds_step_6))
```
**Observaciones**: El p-valore < 0.05 por lo tanto se rechaza normalidad 
multi-variada. Se corresponde con el resultado de los tests de shapiro uni-variados
y los qqplot's.


### 6.5. Test de homocedasticidad multi-variado

```{r}
multi_boxm_test(feat(ds_step_6), target(ds_step_6))
```

**Observaciones**: El p-valor < 0.05 por lo tanto se rechaza la hipótesis 
nula y podemos decir que las variables no son homocedasticas.


### 6.6. Correlaciones entre variables

```{r, fig.align='center'}
plot_correlations(feat(ds_step_6))
```

### 6.7. Análisis completo

```{r, echo=FALSE, fig.align='center'}
ggpairs(feat(ds_step_6), aes(colour = as.factor(target(ds_step_6)), alpha = .4))
```


### 6.8. PCA: Comparación de variables originales con/sin la variable a predecir.

```{r, echo=FALSE, fig.align='center'}
plot_pca_original_variables(ds_step_6)
```


```{r, echo=FALSE, fig.align='center'}
plot_pca_original_variables(feat(ds_step_6))
```


### 6.9. PCA: Con observaciones discriminadas pro clase. Primero quitamos 
outliers para poder ver con mas claridad el biplot.


```{r, fig.align='center'}
plot_robust_pca(ds_step_6)
```


## 7. Train test split

Partimos el dataset en los conjuntos de entrenamiento y prueba. Ademas 
antes de partimos ordenamos las observaciones aleatoriamente para que 
los modelos de clasificación no aprendan secuencia si es que existe 
alguna en el orden original.

```{r}
c(raw_train_set, raw_test_set) %<-% train_test_split(
  ds_step_6, 
  train_size = .8, 
  shuffle    = TRUE
)
```

## 8. Método [SMOTE](https://www.analyticsvidhya.com/blog/2021/04/smote-and-best-subset-selection-for-linear-regression-in-r) para balancear el dataset.

```{r}
# balanced_train_set <- smote_balance(raw_train_set, raw_train_set$Hazardous)
#rm(raw_train_set)
balanced_train_set <- raw_train_set
```

## 9. Escalamos las variables numéricas

Restamos la media y dividimos por el desvío.

```{r}
train_set <- balanced_train_set %>% 
  mutate_at(vars(-Hazardous), ~(scale(.) %>% as.vector))
test_set  <- raw_test_set %>% 
  mutate_at(vars(-Hazardous), ~(scale(.) %>% as.vector))

rm(balanced_train_set)
rm(raw_test_set)
```

## 10. Clasificacion

Antes que nada se debe definir el valor de beta para la métrica **F beta Score**. 
En este problema debemos tener en cuenta dos factores para decidir cual el 
mejor valor de beta:

* Por su naturaleza tenemos un dataset des-balanceado. Existen pocos 
asteroides peligrosos y mucho que no lo son. 

* Por otro lado, es necesario tener en cuenta el costo que conlleva un 
falso positivo y un falso negativo. En este análisis
un falso positivo tiene un costo financiero de chequeo manual. Si clasificamos un asteroide
como peligroso cuando no lo es, tendremos un costo de estudio del mismo, 
pero es es ínfimo en paralización con el costo de un falso negativo.
Un falso negativo se refiere aun asteroide peligroso que clasificamos como no 
peligroso. En este caso existe un posible costo de perdida de vidas humanas y/o heridos. \
Un ejemplo es [el incidente en Cheliábinsk (Rusia)](https://www.youtube.com/watch?v=0lGYeAwzslU) 
en 2013, donde miles de personas resultaron heridas por un asteroide no 
detectado.

Por las razones ya explicadas necesitamos priorizar el recall por sobre
la precisión. Para explicarlo de forma simple, es preferible predecir algun 
negativos como positivos que predecir perfectamente
los positivos a costa de tener falsos negativos.

Finalmente para priorizar el recall elegimos un beta > 1.

```{r}
beta = 2
```

### 10.1. Entrenamos un modelo LDA

```{r}
lda_model <- lda(formula(Hazardous~.), train_set)
```


```{r}
lda_threshold <- search_min_fn_threshold(
  lda_model, 
  feat(test_set), 
  target(test_set),
  xda_predict
)

lda_test_pred  <- xda_predict(lda_model, feat(test_set), lda_threshold)
lda_train_pred <- xda_predict(lda_model, feat(train_set), lda_threshold)
```


```{r, fig.align='center'}
plot_cm(lda_test_pred, target(test_set))
```


```{r, fig.align='center'}
plot_roc(lda_test_pred, target(test_set))
```

```{r}
fbeta_score(lda_test_pred, target(test_set), beta=2)
```

```{r}
lda_model$scaling
```


### 10.2. Entrenamos un modelo QDA

```{r}
qda_model <- qda(formula(Hazardous~.), train_set)
```

```{r}
qda_threshold <- search_min_fn_threshold(
  qda_model, 
  feat(test_set), 
  target(test_set),
  xda_predict
)

qda_test_pred  <- xda_predict(qda_model, feat(test_set), qda_threshold)
qda_train_pred <- xda_predict(qda_model, feat(train_set), qda_threshold)
```


```{r, fig.align='center'}
plot_cm(qda_test_pred, target(test_set))
```

```{r, fig.align='center'}
plot_roc(qda_test_pred, target(test_set))
```


```{r}
fbeta_score(qda_test_pred, target(test_set), beta=2)
```

### 10.3. Entrenamos un modelo RDA

```{r}
rda_model <- rda(formula(Hazardous~.), train_set)
```


```{r}
rda_threshold <- search_min_fn_threshold(
  rda_model, 
  feat(test_set), 
  target(test_set),
  xda_predict
)

rda_test_pred  <- xda_predict(rda_model, feat(test_set),  rda_threshold)
rda_train_pred <- xda_predict(rda_model, feat(train_set), rda_threshold)
```


```{r, fig.align='center'}
plot_cm(rda_test_pred, target(test_set))
```



```{r, fig.align='center'}
plot_roc(rda_test_pred, target(test_set))
```


```{r}
fbeta_score(rda_test_pred, target(test_set), beta=2)
```

### 10.4. Entrenamos un modelo de regresión logística

```{r}
lr_model <- glm(formula(Hazardous~.), train_set, family=binomial)
```

```{r}
lr_threshold <- search_min_fn_threshold(
  lr_model, 
  feat(test_set), 
  target(test_set),
  model_predict
)

lr_test_pred  <- model_predict(lr_model, test_set,  lr_threshold)
lr_train_pred <- model_predict(lr_model, train_set, lr_threshold)
```


```{r, fig.align='center'}
plot_cm(lr_test_pred, target(test_set))
```
```{r}
fp(lr_test_pred, target(test_set))
fn(lr_test_pred, target(test_set))
```

```{r, fig.align='center'}
plot_roc(lr_test_pred, target(test_set))
```

```{r}
fbeta_score(lr_test_pred, target(test_set), beta=2)
```

### 10.5. Entrenamos un modelo SVM

```{r}
svm_model <- svm(formula(Hazardous~.), train_set, kernel = 'radial')
```


```{r}
svm_threshold <- search_min_fn_threshold(
  svm_model, 
  feat(test_set), 
  target(test_set),
  model_predict
)

svm_test_pred  <- model_predict(svm_model, test_set,  svm_threshold)
svm_train_pred <- model_predict(svm_model, train_set, svm_threshold)
```


```{r, fig.align='center'}
plot_cm(svm_test_pred, target(test_set))
```


```{r, fig.align='center'}
plot_roc(svm_test_pred, target(test_set))
```

```{r}
fbeta_score(svm_test_pred, target(test_set), beta=2)
```

### 10.6. Entrenamos un modelo XGBoost


```{r, include=TRUE}
xgboost_model <- xgboost(
 as.matrix(feat(train_set)), 
 target(train_set),
 eta         = 0.2,
 max_depth   = 20,
 nround      = 15000,
 eval_metric = 'logloss',
 objective   = "binary:logistic",
 nthread     = 24,
 verbose     = 0
)
```

```{r, fig.align='center'}
xgb_threshold <- search_min_fn_threshold(
  xgboost_model, 
  feat(test_set), 
  target(test_set),
  xgboost_predict
)

xgb_test_pred  <- xgboost_predict(xgboost_model, feat(test_set),  xgb_threshold)
xgb_train_pred <- xgboost_predict(xgboost_model, feat(train_set), xgb_threshold)
```

```{r}
plot_cm(xgb_test_pred, target(test_set))
```


```{r, fig.align='center'}
plot_roc(xgb_test_pred, target(test_set))
```

```{r}
fbeta_score(xgb_test_pred, target(test_set), beta=2)
```


### 10.7. Comparativa de metricas

### 10.7.1 Metricas seleccionando el threshould con maximo AUR

```{r}
data.frame(
  Test.F2Score.Percent = c(
    fbeta_score(lda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(qda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(rda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(lr_test_pred,  target(test_set), beta=2, show=F),
    fbeta_score(svm_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(xgb_test_pred, target(test_set), beta=2, show=F)
  ),
  Train.F2Score.Percent = c(
    fbeta_score(lda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(qda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(rda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(lr_train_pred,  target(train_set), beta=2, show=F),
    fbeta_score(svm_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(xgb_train_pred, target(train_set), beta=2, show=F)
  ),
  False.Negative = c(
    fn(lda_test_pred, target(test_set)),
    fn(qda_test_pred, target(test_set)),
    fn(rda_test_pred, target(test_set)),
    fn(lr_test_pred,  target(test_set)),
    fn(svm_test_pred, target(test_set)),
    fn(xgb_test_pred, target(test_set))
  ),
  False.positive = c(
    fp(lda_test_pred, target(test_set)),
    fp(qda_test_pred, target(test_set)),
    fp(rda_test_pred, target(test_set)),
    fp(lr_test_pred,  target(test_set)),
    fp(svm_test_pred, target(test_set)),
    fp(xgb_test_pred, target(test_set))
  ),
  Model = c(
    'LDA', 
    'QDA', 
    'RDA', 
    'Regresion Logistica',
    'SVM',
    'XGBoost'
  ),
  Umbral = c(
    lda_threshold, 
    qda_threshold, 
    rda_threshold, 
    lr_threshold,
    svm_threshold,
    xgb_threshold
  )
) %>%
  mutate(
    Test.F2Score.Percent  = round(Test.F2Score.Percent * 100, 3),
    Train.F2Score.Percent = round(Train.F2Score.Percent * 100, 3)
  ) %>%
  dplyr::select(
    False.Negative,
    False.positive,
    Test.F2Score.Percent,
    Train.F2Score.Percent,
    Model,
    Umbral
  ) %>%
  arrange(False.Negative, desc(Test.F2Score.Percent))
```

### 10.7.2 Metricas seleccionando el threshould con minimo False Negative

```{r, fig.align='center'}
lda_threshold <- search_max_aur_threshold(
  lda_model, 
  feat(test_set), 
  target(test_set),
  xda_predict
)

lda_test_pred  <- xda_predict(lda_model, feat(test_set), lda_threshold)
lda_train_pred <- xda_predict(lda_model, feat(train_set), lda_threshold)

qda_threshold <- search_max_aur_threshold(
  qda_model, 
  feat(test_set), 
  target(test_set),
  xda_predict
)

qda_test_pred  <- xda_predict(qda_model, feat(test_set), qda_threshold)
qda_train_pred <- xda_predict(qda_model, feat(train_set), qda_threshold)


rda_threshold <- search_max_aur_threshold(
  rda_model, 
  feat(test_set), 
  target(test_set),
  xda_predict
)

rda_test_pred  <- xda_predict(rda_model, feat(test_set),  rda_threshold)
rda_train_pred <- xda_predict(rda_model, feat(train_set), rda_threshold)

lr_threshold <- search_max_aur_threshold(
  lr_model, 
  feat(test_set), 
  target(test_set),
  model_predict
)

lr_test_pred  <- model_predict(lr_model, test_set,  lr_threshold)
lr_train_pred <- model_predict(lr_model, train_set, lr_threshold)

svm_threshold <- search_max_aur_threshold(
  svm_model, 
  feat(test_set), 
  target(test_set),
  model_predict
)

svm_test_pred  <- model_predict(svm_model, test_set,  svm_threshold)
svm_train_pred <- model_predict(svm_model, train_set, svm_threshold)


xgb_threshold <- search_min_fn_threshold(
  xgboost_model, 
  feat(test_set), 
  target(test_set),
  xgboost_predict
)

xgb_test_pred  <- xgboost_predict(xgboost_model, feat(test_set),  xgb_threshold)
xgb_train_pred <- xgboost_predict(xgboost_model, feat(train_set), xgb_threshold)
```


```{r}
data.frame(
  Test.F2Score.Percent = c(
    fbeta_score(lda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(qda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(rda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(lr_test_pred,  target(test_set), beta=2, show=F),
    fbeta_score(svm_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(xgb_test_pred, target(test_set), beta=2, show=F)
  ),
  Train.F2Score.Percent = c(
    fbeta_score(lda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(qda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(rda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(lr_train_pred,  target(train_set), beta=2, show=F),
    fbeta_score(svm_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(xgb_train_pred, target(train_set), beta=2, show=F)
  ),
  False.Negative = c(
    fn(lda_test_pred, target(test_set)),
    fn(qda_test_pred, target(test_set)),
    fn(rda_test_pred, target(test_set)),
    fn(lr_test_pred,  target(test_set)),
    fn(svm_test_pred, target(test_set)),
    fn(xgb_test_pred, target(test_set))
  ),
  False.positive = c(
    fp(lda_test_pred, target(test_set)),
    fp(qda_test_pred, target(test_set)),
    fp(rda_test_pred, target(test_set)),
    fp(lr_test_pred,  target(test_set)),
    fp(svm_test_pred, target(test_set)),
    fp(xgb_test_pred, target(test_set))
  ),
  Model = c(
    'LDA', 
    'QDA', 
    'RDA', 
    'Regresion Logistica',
    'SVM',
    'XGBoost'
  ),
  Umbral = c(
    lda_threshold, 
    qda_threshold, 
    rda_threshold, 
    lr_threshold,
    svm_threshold,
    xgb_threshold
  )
) %>% 
  mutate(
    Test.F2Score.Percent  = round(Test.F2Score.Percent * 100, 3),
    Train.F2Score.Percent = round(Train.F2Score.Percent * 100, 3)
  ) %>%
  dplyr::select(
    False.Negative,
    False.positive,
    Test.F2Score.Percent,
    Train.F2Score.Percent,
    Model,
    Umbral
  ) %>%
  arrange(False.Negative, desc(Test.F2Score.Percent))
```


### 10.7.3 Metricas seleccionando threshould=0.5

```{r, fig.align='center'}
lda_threshold  <- 0.5
lda_test_pred  <- xda_predict(lda_model, feat(test_set), lda_threshold)
lda_train_pred <- xda_predict(lda_model, feat(train_set), lda_threshold)

qda_threshold  <- 0.5
qda_test_pred  <- xda_predict(qda_model, feat(test_set), qda_threshold)
qda_train_pred <- xda_predict(qda_model, feat(train_set), qda_threshold)


rda_threshold  <- 0.5
rda_test_pred  <- xda_predict(rda_model, feat(test_set),  rda_threshold)
rda_train_pred <- xda_predict(rda_model, feat(train_set), rda_threshold)

lr_threshold  <- 0.5
lr_test_pred  <- model_predict(lr_model, test_set,  lr_threshold)
lr_train_pred <- model_predict(lr_model, train_set, lr_threshold)

svm_threshold  <- 0.5
svm_test_pred  <- model_predict(svm_model, test_set,  svm_threshold)
svm_train_pred <- model_predict(svm_model, train_set, svm_threshold)

xgb_threshold  <- 0.5
xgb_test_pred  <- xgboost_predict(xgboost_model, feat(test_set),  xgb_threshold)
xgb_train_pred <- xgboost_predict(xgboost_model, feat(train_set), xgb_threshold)
```


```{r}
data.frame(
  Test.F2Score.Percent = c(
    fbeta_score(lda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(qda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(rda_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(lr_test_pred,  target(test_set), beta=2, show=F),
    fbeta_score(svm_test_pred, target(test_set), beta=2, show=F),
    fbeta_score(xgb_test_pred, target(test_set), beta=2, show=F)
  ),
  Train.F2Score.Percent = c(
    fbeta_score(lda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(qda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(rda_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(lr_train_pred,  target(train_set), beta=2, show=F),
    fbeta_score(svm_train_pred, target(train_set), beta=2, show=F),
    fbeta_score(xgb_train_pred, target(train_set), beta=2, show=F)
  ),
  False.Negative = c(
    fn(lda_test_pred, target(test_set)),
    fn(qda_test_pred, target(test_set)),
    fn(rda_test_pred, target(test_set)),
    fn(lr_test_pred,  target(test_set)),
    fn(svm_test_pred, target(test_set)),
    fn(xgb_test_pred, target(test_set))
  ),
  False.positive = c(
    fp(lda_test_pred, target(test_set)),
    fp(qda_test_pred, target(test_set)),
    fp(rda_test_pred, target(test_set)),
    fp(lr_test_pred,  target(test_set)),
    fp(svm_test_pred, target(test_set)),
    fp(xgb_test_pred, target(test_set))
  ),
  Model = c(
    'LDA', 
    'QDA', 
    'RDA', 
    'Regresion Logistica',
    'SVM',
    'XGBoost'
  ),
  Umbral = c(
    lda_threshold, 
    qda_threshold, 
    rda_threshold, 
    lr_threshold,
    svm_threshold,
    xgb_threshold
  )
) %>%
  mutate(
    Test.F2Score.Percent  = round(Test.F2Score.Percent * 100, 3),
    Train.F2Score.Percent = round(Train.F2Score.Percent * 100, 3)
  ) %>%
  dplyr::select(
    False.Negative,
    False.positive,
    Test.F2Score.Percent,
    Train.F2Score.Percent,
    Model,
    Umbral
  ) %>%
  arrange(False.Negative, desc(Test.F2Score.Percent))
```



## 11. KMeans Clustering

### 11.1. Primero definimos cuantos grupos utilizar.  

Típica con estimadores de la normal.

```{r}
scaled_data_1 <- feat(ds_step_6) %>% mutate(~(scale(.) %>% as.vector))
```

```{r, fig.align='center'}
clustering_metrics_plot(scaled_data_1)
```

Escalamiento diferente de la típica normal.

```{r}
scaled_data_2 <- apply(
  feat(ds_step_6), 
  2, 
  function(x) { (x - min(x)) / (max(x) - min(x))}
)
```

```{r, fig.align='center'}
clustering_metrics_plot(scaled_data_2)
```


### 11.2. Kmeans

```{r}
n_clusters <- 2
kmeans_model <- kmeans(scaled_data_1, n_clusters)

km_ds_step_6 <- data.frame(ds_step_6)
km_ds_step_6$kmeans <- kmeans_model$cluster
```

### 10.2. biplot


```{r}
# ds_without_outliers <- filter_outliers_m1(km_ds_step_6, max_score=0.5)
ds_without_outliers <- filter_outliers_m2(km_ds_step_6)
```


```{r, fig.align='center'}
plot_robust_pca(
  ds_without_outliers %>% dplyr::select(-kmeans),
  groups = factor(ds_without_outliers$kmeans),
)
```



## 11.3 Hierarchical Clustering

Matriz de distancias euclídeas 
```{r}
mat_dist <- dist(x = ds_step_6, method = "euclidean") 
```


Dendrogramas (según el tipo de segmentación jerárquica aplicada)  
```{r}

hc_complete <- hclust(d = mat_dist, method = "complete") 
hc_average  <- hclust(d = mat_dist, method = "average")
hc_single   <- hclust(d = mat_dist, method = "single")
hc_ward     <- hclust(d = mat_dist, method = "ward.D2")
```

Calculo del coeficiente de correlación cofenetico

```{r}
cor(x = mat_dist, cophenetic(hc_complete))
cor(x = mat_dist, cophenetic(hc_average))
cor(x = mat_dist, cophenetic(hc_single))
cor(x = mat_dist, cophenetic(hc_ward))
```

Construcción de un dendograma usando los resultados de la técnica de Ward
```{r, fig.align='center'}
n_clusters <- 2

graphics.off()
plot(hc_ward )
rect.hclust(hc_ward, k=n_clusters, border="red")
```

```{r}
hc_ds <- data.frame(ds_step_6)
hc_ds$her_ward <- cutree(hc_ward, k=n_clusters)
```

```{r}
# ds_without_outliers <- filter_outlier_m1(hc_ds, max_score=0.57)
ds_without_outliers <- filter_outliers_m2(hc_ds)
```

```{r, fig.align='center'}
plot_robust_pca(
  ds_without_outliers %>% dplyr::select(-her_ward),
  groups = factor(ds_without_outliers$her_ward),
  colours=c("orange","cyan","blue","magenta","yellow","black"),
  labels=c("grupo 1", "grupo 2","grupo 3","grupo 4","grupo 5","grupo 6")
)
```








